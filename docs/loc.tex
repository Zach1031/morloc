\documentclass[12pt]{article}

\begin{document}

\section{Templates}

The core functions of Loc are manifold. These functions take no arguments.
They are conglomerations of the following elements:

\begin{table}[htpb]
  \centering
  \caption{Elements of manifolds}
  \label{tab:elements_of_manifolds}
  \begin{tabular}{l|l}
element & description \\
\hline
pure    & pure data transformation function                                         \\
cache   & cache output with 4 operations: 'has', 'get', 'put', and 'del'            \\
inputs  & list of other manifolds from which input is requested                     \\
checks  & list of validator manifolds, which return booleans                        \\
open    & function that extracts list of inputs from list of input containers       \\
pass    & executes the pure function (locally, send to a cluster, whatever you say) \\
pack    & packs the output in a container                                           \\
fail    & produces the output in case of an error                                   \\
effects & list of manifolds to call after caching result
  \end{tabular}
\end{table}

A manifold itself has the form

\begin{verbatim}
m =
    if
    ( cache_has m )
    ( cache_get m )
    ( 
        Mb = if
        ( [check] )
        (
            Ma = map inputs,
            a = map open Ma,
            b = pass pure *a **args,
            map effects b 
            pack Ma b
        )
        (
           fail
        ),
        cache_put Mb,
        map hooks,
        Mb
    )
\end{verbatim}

\begin{verbatim}
m =
  (
    [begin]
    (?
      cache_condition,
      get_cached,
      ( 
        [prehooks]
        (?
          [evaluation_condition],
          (
            Mb = function( [open input] )
            b = unpack(Mb)
            M = context(Mb)
            [(do_to_context M)]
            [(do_to_data b)]
            [(do_to_both Mb)]
            (?
              [inner_fail_conditions, b, M],
              [inner_success, b, M],
              [inner_fail, b, M]
              Mb = (inner_fail_output, b, M)
            )
          ),
          (
            Mb = fail_output
            [fail_effect]
            [fail_effect_p Mb]
          )
          cache Mb
        )
        [posthooks]
      )
    )
    [end]
  )
\end{verbatim}


\section{Expectations for the backends}

The Loc compiler translates Loc code into an intermediate language (Loc
Intermediate Language, LIL) that lists the steps need to build a program. It
is the job of the backend to interpret LIL into working code in an output
language (OL). The process of adding support for new languages will be
simplified if there is a roughly one-to-one correlation between instructions in
LIL and functions in the backend.

The destination language should have an index of typed functions. It should
also maintain all manifolds in a containter where they can access one another.

The manifolds themselves can be represented in many ways. In languages with
good metaprograming support, like R, they may be functions which are modified
as LIL is interpreted. In OOP languages, they may be objects.

\begin{itemize}

  \item EMIT(string ID) - add a new manifold with label ID to the manifold set

  \item FUNC(string ID, string FUNC) - look of FUNC in the function database,
    set ID to this function

  \item INPM(string ID1, int i, string ID2) - link ID2 as a the ith positional
    argument of ID1

  \item INPP(string ID1, int i, string ID2) - link the eval(value) as the ith
    positional argument of ID1

  \item NORM - stub

  \item INPD - stub

  \item CACHE(string ID, string C) - wrap manifold ID in the cache paradigm C
    (caches are not singular functions, but rather contain at least 3 elements:
    CHECK, GET, and PUT)

  \item EFCT(string ID, string F) - append function F to the effect list of manifold ID

\begin{verbatim}
    F :: (a -> *) 
\end{verbatim}

  \item CHECK(string ID, string F) - append function F to the check list of manifold ID

\begin{verbatim}
    F :: (a -> Bool)  
\end{verbatim}

  \item OPEN(string ID, string F) - append function F to open list of manifold
    ID (which must be of length 0, 1 or the number of input functions)

\begin{verbatim}
    F :: (Ma -> a) 
\end{verbatim}

  \item PACK(string ID, string F) - set pack function of manifold ID to F
    
\begin{verbatim}
    F :: (Ma -> b -> Mb)
\end{verbatim}

  \item PASS(string ID, string F) - set pass function of manifold ID to F

\begin{verbatim}
    F :: (f -> [inputs] -> [args] -> b)
\end{verbatim}

  \item FAIL(string ID, string F) - set the failure function of manifold ID to F

\begin{verbatim}
    F :: (NULL -> Mb)
\end{verbatim}

  \item DOC(string ID, string doc) - sets the documentation of manifold ID to doc

  \item ARG(string ID, string key, string val) - sets argument key of manifold ID to val

\end{itemize}

\section{Approach}

There are two ways a workflow can be viewed: a graph of functions, or a graph
of data. Of course the two can also be merged. If the functions are typed, the
data graph is implicit in the function graph, and can be extracted from it. An
anonymous function graph is also implicit in a data graph.

\section{On directions}

I can write paths in two directions, from the bottom up, or from top down.

\begin{verbatim}
FinalResult <-- Piece3 <-- Piece1 Piece 2
\end{verbatim}

Or

\begin{verbatim}
Piece1 Piece2 --> Piece3 --> FinalResult
\end{verbatim}

The latter is reminiscent of a familiar shell pipeline. It mirrors the flow of
data from well to sink. The former is like mathematical composition.

A deeper example

\begin{verbatim}
FinalResult . ResultA ResultB
ResultA . X Y Z
X . E R T
Y . U
Z . whatever . yeah
ResultB . W . R
\end{verbatim}

Where $.$ represents composition. Phrases like $f . a b$ indicates,
$f(a(),b())$. Since we are dealing with manifolds, no arguments are passed to
a and b, they know what to do. Multiple inputs prevents further chaining. $f . a b . c$ doesn't make sense. It could possibly mean that that $a$ and $b$
both request input from $c$, but that is perhaps not very useful. It is better,
probably, to consider these branches as chain ends. Then drop a level into the
definitions of $a$ and $b$.

\begin{verbatim}
f . x y;
x = a . c;
y = b . d . (e . i) . f . g h;
\end{verbatim}

Where $c$, $g$, $i$, and $h$ are wells, and $f$ is a sink.

There is a recursive beauty to this, and it allows very clean abstractions, it
places the final goal at the top. It also clearly expresses the pull approach
the manifolds follow. It avoids the weird situation where I have to recurse to
the end of a path to find the sinks.

But why choose? I can allow both.

What if they are both used in the same statement? Should that be legal?

\begin{verbatim}
D <-- (A --> B) C 
\end{verbatim}

\begin{verbatim}
C <-- A --> B
\end{verbatim}

Hmm, $-->$ should have higher precedence. Still mixing is pretty convoluted.

\begin{verbatim}
D <-- (B <-- A) --> C
\end{verbatim}


\begin{verbatim}
Main = Analyze . Join . Map . Filter . Divide . Retrieve
\end{verbatim}


sqrt(mean(runif(x)))

sqrt . mean . runif:1

log . median . runif:1


Nahhh, mixing the two needs to be illegal.

Why not express these as compositions?


\section{Composite output}

\begin{verbatim}
A --> (B, C, D)
\end{verbatim}

Where A has three outputs, say of types [b,c,d]. For these, we automatically
generate the linker functions B, C, and D.

\section{On failure}

There are three kinds of failure.

\begin{itemize}
  \item a validator trips, the fail function is called before the run function has
     even been called.
  \item run functions raises an exception.
  \item the run function succeeds, but the output is invalid (as assessed by
     a post-validator).
\end{itemize}

Currently, I directly handle failure of the first kind. The other two kinds can
be handled by writing checks into the pack function and passing the results in
the trappings of the pure output. This would be the monadic solution.

To this point, I have mostly thought about validators as operating on the
values of manifolds. But equally important, perhaps, is validation of
arguments. The manifold validators check the environment and the values of
other manifolds. But they cannot see the arguments of a particular manifold.
Perhaps one solution would be for a manifold to access another manifold by
reference, not value. That is, rather than accessing the stuff in the cache, it
accesses the manifold metadata.

No, there is a better way. Again, monads. I can pack the argument list into the
monad. Then you just change the unpack function of the validator to take the
argument list rather than just the pure value.

\section{Conditionals}

Partitioning data is an important part of many workflows. Morloc needs a good
method for expressing binary trees. It isn't hard: $V1 ? V2 ? A, B, V3 ? C, D$ etc
works fine. The grammar is:

\begin{verbatim}
cexp
  : COND VAL  VAL
  | COND cexp VAL
  | COND VAL  cexp
  | COND cexp cexp
\end{verbatim}

This allows clean expression of binary trees, e.g.

\begin{verbatim}
  V1 ? A,
  V2 ?
     V3 ? B,
     V4 ? F, G,
     V5 ? H,
     V6 ? I, J
  . x
\end{verbatim}

Here each V. conditional statement is a function of x, y, and z. If the
function returns true, the left path is evaluated. When a leaf is reached, the
leaf function is called (on x,y,z by default).

This would compile into pseudocode like the following:

\begin{verbatim}
if (V1 x)
    A x
elif (V2 x)
    if (V3 x)
        B x
    elif (V4 x)
        F x
    else
        G x
else
    if (V5 x)
        H x
    elif (V6 x)
        I x
    else
        J x
where
x :: Foo
V1,V1,... :: Foo -> Bool
A,B,C,D,E,F,G,H,I,J :: Foo -> a
\end{verbatim}

But how to loop this? That is, what if x is a list?

I'll discuss the possibilities in the context of this simple example:

\begin{verbatim}
V ? A, B . x
\end{verbatim}

This operation has the signature:

\begin{verbatim}
(V -> Foo -> Bool) -> (A -> Foo -> a) -> (B -> Foo -> b) -> [Foo] -> ([a], [b])
\end{verbatim}

There are some variants in the first expression:

\begin{verbatim}
V   :: Foo -> Bool      -- e1
V'  :: [Foo] -> Bool    -- e2
V'' :: [Foo] -> [Bool]  -- e3
\end{verbatim}

For e1, Loc would just have to map V across x in the compiled code. The
difference between e2 and e3 is more significant. e2 reduces the entire vector
to a single boolean. This will result in only a single leaf being selected and
all data being processed by the one function. e3 maps list to list, leading to
the data being partitioned between leafs. e3 would also return an ambiguous
type (unless all A-J had the same signatures).

Both uses are reasonable, and both should be allowed. But how to syntactically
distinguish them? This brings me back to the ever troublesome loop issue.

\section{On inputs, outputs and parameters}

Since Loc is a workflow language, a multifurcating relative of linear shell
pipelines, connecting function inputs to function outputs is of prime
importance. However their are other inputs to a function, the constant
parameters. Take for example GNU grep. Grep has the general form

\begin{verbatim}
Grep :: [Line] -> Pattern -> [Line]
\end{verbatim}

However Grep also has the flag {\it --invert-match}. You can add this parameter to the signature, of course:

\begin{verbatim}
Grep :: [Line] -> Pattern -> Bool -> [Line]
\end{verbatim}

It has dozens of other options; adding all of them to the signature dilute the
clarity of the original. There are a several solutions

\begin{itemize}
 \item Have a different name for each combination of arguments, e.g. grep, vgrep,
    egrep. But this quickly bloats the namespace.
 \item Make functions more atomic, then transform them, e.g. `invert grep`, but
    this requires extensive reworking of the grep implementation, something
    I want to avoid when possible. 
 \item Separate inputs from parameters. This is basically a general way to do
    option n2. Adding options changes the way the function works, but preserves
    the function signature.
\end{itemize}

I am going with n3. Continuing with the grep example, there are options in GNU
grep that alter the function type. For example, `--count` changes the signature
to

\begin{verbatim}
Grep' :: [Line] -> Pattern -> Integer
\end{verbatim}

and `--file` changes the type to

\begin{verbatim}
Grep'' :: [Line] -> File -> [Line]
\end{verbatim}

Of course you can also have both

\begin{verbatim}
Grep''' :: [Line] -> File -> Integer
\end{verbatim}

GNU grep also allows you to read from a file, so for each Grep variant above,
the first argument can be swapped with `[File]`.

\begin{verbatim}
FGrep    :: [File] -> Pattern -> [Line]
FGrep'   :: [File] -> Pattern -> Integer
FGrep''  :: [File] -> File -> [Line]
FGrep''' :: [File] -> File -> Integer
\end{verbatim}

So even after corralling type-conserving parameters into the @arg section, we
still have a combinatoric explosion. The problem is that grep does too much. We
should delegate reading files and counting lines to dedicated functions:

\begin{verbatim}
grep (read "world.txt") "waldo"
length . grep (read "world.txt") "waldo"
unnest . map (grep (read "world.txt")) (read "patterns.txt")
\end{verbatim}

The last example uses currying, something not implemented in Loc. Also
something that I can't literally implement at all in Loc since it would require
changing client code (maybe, thar be hacks ...). However, if I create a `map`
builtin, I can compile this with a loop calling `grep (read "world.txt) x` for
all x in `(read "patterns.txt")`. However, this is inefficient. Grep has
optimizations for searching multiple patterns (or if it doesn't, it should) and
also this may require multiple loadings of the input document. This is a common
problem where vectorization is optimized and problems can't be efficiently
atomized. It is a very common problem in compiling R code. One solution to the
Grep issue would be to define Grep as

\begin{verbatim}
Grep :: [Line] -> [Pattern] -> [Line]
\end{verbatim}

So it is always vectorized.

\section{On effect}

What should be passed to the effect functions. There are several possibilities,
all of them useful in certain contexts:

Option 1: pass nothing. The effect functions are manifolds, they can be
elaborate entities, constructed in the Morloc path section. In this way, they are
an orthogonal dimension to the pure path through the data.

Option 2: pass b (the unpackaged output). This would be extremely useful for
simple effects, like a print statement. Then builtin functions of language can
be called, without needing to be wrapped in manifolds, without the boilerplate.

Option 3: pass Mb (the packaged output). Useful is dependent on how the state
being passed in the package is being used in the pipeline.

Option 4: pass [a] and b. Some analyses might want to compare the output and
input. Of course this could be done with manifold calls.

Option 5: Option 1-4. Allow everything. Build some syntax to specify which
function should be used.

\section{A word on the future}

Loc is dependent on infrastructure that does not yet exist. It is a weak
dependency, since Loc can work with any set of pure functions. But it would be
most powerful in the context of a functional database. Hoogle is the prototype.

The functional database obviously needs to allow lookup based on exact type
signatures. It also needs to understand the ontology, inheritance of types,
algebras. The starables of a type (orderable, comparable, printable, iterable,
numerable, etc). It needs to be able to trace paths between types, to enumerate
all possible paths between a specified set of inputs and outputs. There should
be compose and decompose operations. Slightly unrelated, but we should also
have methods to store and study typed workflows.

Such a database would consist of the function code, an ontology (specified in
Loc), and the signatures for each function (also in Loc).

\section{A word on Galaxy, KBase, IPlant desktop, and their ilk}

These are similar to Loc in that they allow linking of functional units and
setting of their parameters.

Their point-and-click interfaces present a specialized subset of the
functionallity of a subset of all programs selected form a subset of all
fields. They cater to the non-programmer, offering "user friendly" access to
common workflows within specific fields. They sacrifice power for muggle
usability. Loc is far more general and allows user-written code. It could serve
as a basis for a muggle workflow engine, but is still useful to the programmer
(well, ok, it isn't useful to anyone yet).

The Galaxy class programs focus on linking wrappers for independent programs.
In contrast, Loc is a metaprogramming language for creating pure code. Since
Loc functions may be wrappers for standalone programs, Loc supersets the Galaxy
class. Loc can interface with the entire function set of any language with no
boilerplate (it isn't safe to do this, since you should at least have a type
signature). I should temper this by specifying the limitations of Loc,
specifically, it requires pure functions with types that are invariant to
parameter choice. This may necessitate writing wrappers for functions, for
example see the discussion of GNU grep above.

\section{Relation to lambda calculus}

Lambda calculus distinguishes between variables and expressions. In Morloc there
are no variables. But there are expressions that take no inputs, these play the
role of variables.

The grammar of Morloc is

\begin{verbatim}
  E = m|(E)|EE|E.E
\end{verbatim}

Where $E$ is an expression and $m$ is a manifold.

Here are the rules for conversion to $\lambda$-expressions:

\begin{itemize}
  \item $E = \lambda p . M$
  \item $EE = \{ \lambda p . M, \quad \lambda p . N \}$
  \item $E.E = ( \lambda p . M ) ( \lambda p . N )$
\end{itemize}

Where $p = \O | E$. The expressions can take no inputs, these expressions are
like variables in $\lambda$-calculus.

The outputs of an expression are:

\begin{itemize}
  \item $O(m) = m$
  \item $O( (M) ) = O(M)$
  \item $O(M.N) = O(M)$
  \item $O(MN) = O(M) \cup O(N)$
\end{itemize}

The outputs are the manifolds themselves.

NOTE: I do not allow a nested expression to produce multiple outputs in Morloc.

Likewise, the receivers of input to an expression are:

\begin{itemize}
  \item $I(m) = m$
  \item $I( (M) ) = I(M)$
  \item $I(M.N) = I(N)$
  \item $I(MN) = I(M) \cup I(N)$
\end{itemize}

Every manifold wraps a single pure function. This function has $k$ positional
parameters. The number of inputs may be either 0, in which case the manifold is
\textit{open} or $k$, in which case the manifold is \textit{closed}.

This open/closed terminology draws from TTFP (Nederpelt, Geuvers).

\end{document}
